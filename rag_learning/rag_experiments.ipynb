{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c19d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"I:\\\\sridhar\\\\rag_learning\\\\students_table_with_unique_remarks.csv\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3e8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66acb418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roll_number</th>\n",
       "      <th>student_name</th>\n",
       "      <th>department</th>\n",
       "      <th>remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Amit demonstrates strong logical thinking and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Priya Verma</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Priya is very detail-oriented, shows creativit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Rahul Mehta</td>\n",
       "      <td>Mechanical</td>\n",
       "      <td>Rahul has a practical approach to solving mech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Sneha Nair</td>\n",
       "      <td>Civil</td>\n",
       "      <td>Sneha has strong analytical skills, performs e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vikram Singh</td>\n",
       "      <td>Electrical</td>\n",
       "      <td>Vikram is highly motivated in power systems, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   roll_number  student_name        department  \\\n",
       "0            1   Amit Sharma  Computer Science   \n",
       "1            2   Priya Verma       Electronics   \n",
       "2            3   Rahul Mehta        Mechanical   \n",
       "3            4    Sneha Nair             Civil   \n",
       "4            5  Vikram Singh        Electrical   \n",
       "\n",
       "                                             remarks  \n",
       "0  Amit demonstrates strong logical thinking and ...  \n",
       "1  Priya is very detail-oriented, shows creativit...  \n",
       "2  Rahul has a practical approach to solving mech...  \n",
       "3  Sneha has strong analytical skills, performs e...  \n",
       "4  Vikram is highly motivated in power systems, a...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96500d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    Document(page_content=str(row[\"remarks\"]), metadata={\"student\": str(row[\"student_name\"])})\n",
    "    for _, row in df.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7da78358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "\n",
    "# path to your csv\n",
    "file_path = \"I:\\\\sridhar\\\\rag_learning\\\\students_table_with_unique_remarks.csv\"\n",
    "encoding=\"utf-8\"\n",
    "\n",
    "# load CSV as documentsdocu\n",
    "loader = CSVLoader(file_path=file_path, encoding=encoding)\n",
    "documents = loader.load()\n",
    "\n",
    "print(len(documents))  # number of rows loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78434285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50,  # adjust for your embedding model\n",
    "    chunk_overlap=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f773ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba0290a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    remarks = str(row.get(\"remarks\", \"\"))         # Initialize to empty string if no text present\n",
    "    roll_number = str(row.get(\"roll_number\", \"\")) # Initialize to empty string if no text present\n",
    "    student_name =str(row.get(\"student_name\", \"\"))\n",
    "    department=str(row.get(\"department\", \"\"))\n",
    "    chunks=splitter.split_text(remarks)\n",
    "#    print(len(chunks))\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        docs.append({\n",
    "            \"row_index\":  idx,\n",
    "            \"chunk_index\": i,\n",
    "            \"roll_number\": row.get(\"roll_number\",100),\n",
    "            \"chunk\": chunk\n",
    "            })\n",
    "chunks_df=pd.DataFrame(docs)\n",
    "#print(chunks_df.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8f78816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>chunk_index</th>\n",
       "      <th>roll_number</th>\n",
       "      <th>chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Amit demonstrates strong logical thinking and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>and consistently performs well in coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>challenges, making him a standout in Computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Science.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Priya is very detail-oriented, shows creativit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_index  chunk_index  roll_number  \\\n",
       "0          0            0            1   \n",
       "1          0            1            1   \n",
       "2          0            2            1   \n",
       "3          0            3            1   \n",
       "4          1            0            2   \n",
       "\n",
       "                                               chunk  \n",
       "0      Amit demonstrates strong logical thinking and  \n",
       "1           and consistently performs well in coding  \n",
       "2      challenges, making him a standout in Computer  \n",
       "3                                           Science.  \n",
       "4  Priya is very detail-oriented, shows creativit...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7502ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_df.to_csv(\"I:\\\\sridhar\\\\rag_learning\\\\students_table_with_unique_remarks_chunks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af00c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, sys\n",
    "\n",
    "# Increase the max allowed size for a field\n",
    "\n",
    "csv.field_size_limit(1310720)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a99abfb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error loading I:\\sridhar\\rag_learning\\documents.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mError\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mi:\\Sridhar\\rag_learning\\.venv\\Lib\\site-packages\\langchain_community\\document_loaders\\csv_loader.py:135\u001b[39m, in \u001b[36mCSVLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m.file_path, newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[38;5;28mself\u001b[39m.encoding) \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__read_file(csvfile)\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mi:\\Sridhar\\rag_learning\\.venv\\Lib\\site-packages\\langchain_community\\document_loaders\\csv_loader.py:155\u001b[39m, in \u001b[36mCSVLoader.__read_file\u001b[39m\u001b[34m(self, csvfile)\u001b[39m\n\u001b[32m    154\u001b[39m csv_reader = csv.DictReader(csvfile, **\u001b[38;5;28mself\u001b[39m.csv_args)\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcsv_reader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mI:\\Users\\sridh\\anaconda3\\Lib\\csv.py:111\u001b[39m, in \u001b[36mDictReader.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    110\u001b[39m     \u001b[38;5;28mself\u001b[39m.fieldnames\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m row = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.reader)\n\u001b[32m    112\u001b[39m \u001b[38;5;28mself\u001b[39m.line_num = \u001b[38;5;28mself\u001b[39m.reader.line_num\n",
      "\u001b[31mError\u001b[39m: field larger than field limit (131072)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# load CSV as documentsdocu\u001b[39;00m\n\u001b[32m      9\u001b[39m loader = CSVLoader(file_path=file_path, encoding=encoding)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m documents = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(documents))  \u001b[38;5;66;03m# number of rows loaded\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mi:\\Sridhar\\rag_learning\\.venv\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py:43\u001b[39m, in \u001b[36mBaseLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[32m     38\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load data into Document objects.\u001b[39;00m\n\u001b[32m     39\u001b[39m \n\u001b[32m     40\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[33;03m        the documents.\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mi:\\Sridhar\\rag_learning\\.venv\\Lib\\site-packages\\langchain_community\\document_loaders\\csv_loader.py:151\u001b[39m, in \u001b[36mCSVLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    149\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Error loading I:\\sridhar\\rag_learning\\documents.csv"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "import chardet\n",
    "\n",
    "# path to your csv\n",
    "file_path = \"I:\\\\sridhar\\\\rag_learning\\\\documents.csv\"\n",
    "encoding=\"utf-8\"\n",
    "\n",
    "# load CSV as documentsdocu\n",
    "loader = CSVLoader(file_path=file_path, encoding=encoding)\n",
    "documents = loader.load()\n",
    "\n",
    "print(len(documents))  # number of rows loaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34badbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # adjust for your embedding model\n",
    "    chunk_overlap=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab81ab4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6aa852de",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f5c4340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16e1c610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "4\n",
      "31\n",
      "27\n",
      "15\n",
      "20\n",
      "47\n",
      "25\n",
      "15\n",
      "23\n",
      "14\n",
      "88\n",
      "27\n",
      "78\n",
      "20\n",
      "50\n",
      "277\n",
      "35\n",
      "80\n",
      "95\n",
      "(1972, 4)\n"
     ]
    }
   ],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    text = str(row.get(\"text\", \"\"))         # Initialize to empty string if no text present\n",
    "    source = str(row.get(\"source_url\", \"\")) # Initialize to empty string if no text present\n",
    "    chunks=splitter.split_text(text)\n",
    "    print(len(chunks))\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        docs.append({\n",
    "            \"row_index\":  idx,\n",
    "            \"chunk_index\": i,\n",
    "            \"source\": row.get(\"source_url\"),\n",
    "            \"chunk\": chunk\n",
    "            })\n",
    "chunks_df=pd.DataFrame(docs)\n",
    "print(chunks_df.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ad79b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>chunk_index</th>\n",
       "      <th>source</th>\n",
       "      <th>chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>19</td>\n",
       "      <td>89</td>\n",
       "      <td>https://arxiv.org/pdf/2404.10981</td>\n",
       "      <td>Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>19</td>\n",
       "      <td>90</td>\n",
       "      <td>https://arxiv.org/pdf/2404.10981</td>\n",
       "      <td>pages 9414–9423. Association for Computational...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>19</td>\n",
       "      <td>91</td>\n",
       "      <td>https://arxiv.org/pdf/2404.10981</td>\n",
       "      <td>Representations (ICLR).\\nFangyuan Xu, Weijia S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>19</td>\n",
       "      <td>92</td>\n",
       "      <td>https://arxiv.org/pdf/2404.10981</td>\n",
       "      <td>2369–2380. Association for Computational Lingu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>19</td>\n",
       "      <td>93</td>\n",
       "      <td>https://arxiv.org/pdf/2404.10981</td>\n",
       "      <td>China, July 25-30, 2020, pages 1933–1936. ACM....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>19</td>\n",
       "      <td>94</td>\n",
       "      <td>https://arxiv.org/pdf/2404.10981</td>\n",
       "      <td>Computational Linguistics.\\nYi Yuan, Haohe Liu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_index  chunk_index                            source  \\\n",
       "1966         19           89  https://arxiv.org/pdf/2404.10981   \n",
       "1967         19           90  https://arxiv.org/pdf/2404.10981   \n",
       "1968         19           91  https://arxiv.org/pdf/2404.10981   \n",
       "1969         19           92  https://arxiv.org/pdf/2404.10981   \n",
       "1970         19           93  https://arxiv.org/pdf/2404.10981   \n",
       "1971         19           94  https://arxiv.org/pdf/2404.10981   \n",
       "\n",
       "                                                  chunk  \n",
       "1966  Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz...  \n",
       "1967  pages 9414–9423. Association for Computational...  \n",
       "1968  Representations (ICLR).\\nFangyuan Xu, Weijia S...  \n",
       "1969  2369–2380. Association for Computational Lingu...  \n",
       "1970  China, July 25-30, 2020, pages 1933–1936. ACM....  \n",
       "1971  Computational Linguistics.\\nYi Yuan, Haohe Liu...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_df.tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "903c8a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_df.to_csv(\"I:\\\\sridhar\\\\rag_learning\\\\chunks.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9cc51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Document(\n",
    "    page_content=\"The actual text of the document\",\n",
    "    metadata={\"source\": \"example.csv\", \"chunk\": 1}\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbb9f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "        docs.append(\n",
    "            Document(\n",
    "                page_content=chunk,\n",
    "                metadata={\n",
    "                    \"source_url\": source,\n",
    "                    \"row_index\": idx,   # keep track of original row\n",
    "                    \"chunk\": i\n",
    "                }\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3829d147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document   # or from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings  # or HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc79a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"I:\\\\Sridhar\\\\rag_learning\\\\documents.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87902269",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc0b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    Document(page_content=str(row[\"text\"]), metadata={\"source\": str(row[\"source_url\"])})\n",
    "    for _, row in df.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48fd6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a28916",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_docs = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a09ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_data = []\n",
    "for i, doc in enumerate(chunked_docs):\n",
    "    chunk_data.append({\n",
    "        \"source\": doc.metadata[\"source\"],\n",
    "        \"chunk_index\": i,\n",
    "        \"chunk\": doc.page_content\n",
    "    })\n",
    "\n",
    "chunk_df = pd.DataFrame(chunk_data)\n",
    "print(chunk_df.head(10))  # first 10 chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4050fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df.to_csv(\"I:\\\\Sridhar\\\\rag_learning\\\\chunked_docs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1f9a495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "#from langchain.schema import Document\n",
    "from langchain_core.documents import Document\n",
    "df=pd.read_csv(\"I:\\\\sridhar\\\\rag_learning\\\\documents.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85285fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_url\n",
       "https://enterthegungeon.fandom.com/wiki/Bullet_Kin                                                                                            1\n",
       "https://www.dropbox.com/scl/fi/ljtdg6eaucrbf1aksw5rm/c2%20-%20session%2050%20-%20underground.docx?rlkey=ioqwgkd14i5xk20i3fp38nzgs&e=1&dl=0    1\n",
       "https://bytes-and-nibbles.web.app/bytes/stici-note-part-1-planning-and-prototyping                                                            1\n",
       "https://github.com/llmware-ai/llmware                                                                                                         1\n",
       "https://docs.marimo.io/recipes.html                                                                                                           1\n",
       "https://towardsdatascience.com/how-to-maximize-your-impact-as-a-data-scientist-3881995a9cb1                                                   1\n",
       "https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683                                                                           1\n",
       "https://bg3.wiki/wiki/The_Emperor                                                                                                             1\n",
       "https://whattocook.substack.com/p/so-into-northern-spain                                                                                      1\n",
       "https://dmtalkies.com/the-zone-of-interest-ending-explained-and-summary-2023-film/                                                            1\n",
       "https://www.loonyparty.com/about/policy-proposals/                                                                                            1\n",
       "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/                                                                               1\n",
       "https://gleam.run/cheatsheets/gleam-for-python-users/                                                                                         1\n",
       "https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e                                                                         1\n",
       "https://blog.reedsy.com/short-story/a3gstd/                                                                                                   1\n",
       "http://www.chakoteya.net/DoctorWho/40-1.html                                                                                                  1\n",
       "https://stardewvalleywiki.com/Version_History                                                                                                 1\n",
       "https://alanwake.fandom.com/wiki/Alan_Wake_2                                                                                                  1\n",
       "https://www.polygon.com/23691206/best-fantasy-books-sci-fi-2023                                                                               1\n",
       "https://arxiv.org/pdf/2404.10981                                                                                                              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source_url'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06c000b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>source_url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://enterthegungeon.fandom.com/wiki/Bullet...</td>\n",
       "      <td>Bullet Kin\\nBullet Kin are one of the most com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.dropbox.com/scl/fi/ljtdg6eaucrbf1a...</td>\n",
       "      <td>---The Paths through the Underground/Underdark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://bytes-and-nibbles.web.app/bytes/stici-...</td>\n",
       "      <td>Semantic and Textual Inference Chatbot Interfa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://github.com/llmware-ai/llmware</td>\n",
       "      <td>llmware\\n\\nBuilding Enterprise RAG Pipelines w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://docs.marimo.io/recipes.html</td>\n",
       "      <td>Recipes\\nThis page includes code snippets or “...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                         source_url  \\\n",
       "0      0  https://enterthegungeon.fandom.com/wiki/Bullet...   \n",
       "1      1  https://www.dropbox.com/scl/fi/ljtdg6eaucrbf1a...   \n",
       "2      2  https://bytes-and-nibbles.web.app/bytes/stici-...   \n",
       "3      3              https://github.com/llmware-ai/llmware   \n",
       "4      4                https://docs.marimo.io/recipes.html   \n",
       "\n",
       "                                                text  \n",
       "0  Bullet Kin\\nBullet Kin are one of the most com...  \n",
       "1  ---The Paths through the Underground/Underdark...  \n",
       "2  Semantic and Textual Inference Chatbot Interfa...  \n",
       "3  llmware\\n\\nBuilding Enterprise RAG Pipelines w...  \n",
       "4  Recipes\\nThis page includes code snippets or “...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0b9d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import getpass\n",
    "#import os\n",
    "\n",
    "#if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "#  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb165918",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4980eb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66409a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
